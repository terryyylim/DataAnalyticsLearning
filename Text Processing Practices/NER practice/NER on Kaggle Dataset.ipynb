{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice on NER\n",
    "This is a simple tutorial to recap and better understand application of NER in NLP problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Take note of encoding\n",
    "pd_dataset = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect dataset\n",
    "Since the first column has labels only on the first word of each sentence, I'll use the 'ffill' method to fill forward the data to other rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset.fillna(method=\"pad\", inplace=True) # Can use either pad/ffill\n",
    "\n",
    "# top 5 rows\n",
    "pd_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS Tag\n",
       "1048570  Sentence: 47959       they  PRP   O\n",
       "1048571  Sentence: 47959  responded  VBD   O\n",
       "1048572  Sentence: 47959         to   TO   O\n",
       "1048573  Sentence: 47959        the   DT   O\n",
       "1048574  Sentence: 47959     attack   NN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last 5 rows\n",
    "pd_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    object\n",
       "Word          object\n",
       "POS           object\n",
       "Tag           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datatypes of columns\n",
    "pd_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35178"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(pd_dataset['Word'].values))\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, we can see that there are 47959 sentences and 35178 unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a class to retrieve sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceConcatenator(object):\n",
    "    def __init__(self, dataset):\n",
    "        self.sentence_pos = 1\n",
    "        self.dataset = dataset\n",
    "        self.is_empty = False\n",
    "        \n",
    "    def get_next_word(self):\n",
    "        try:\n",
    "            # Getting all words in a particular sentence through checking first column data\n",
    "            sentence = self.dataset[self.dataset['Sentence #'] == \"Sentence: {}\".format(self.sentence_pos)]\n",
    "            self.sentence_pos += 1\n",
    "            return sentence['Word'].tolist(), sentence['POS'].tolist(), sentence['Tag'].tolist()\n",
    "        except:\n",
    "            # Case: No dataset\n",
    "            self.empty = True\n",
    "            return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conca = SentenceConcatenator(pd_dataset)\n",
    "sentence, pos, tag = conca.get_next_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memorization\n",
    "The baseline would be to remember the most common named entity for each word and predict that. In the event where we don't know the word, we would just predict 'O'.\n",
    "\n",
    "Links to libraries:<br>\n",
    "1) BaseEstimator: http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html <br>\n",
    "2) TransformerMixin: http://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html\n",
    "\n",
    "<strong>BaseEstimator</strong> provides a default implementation for the <i>get_params</i> and <i>set_params</i> methods. This is useful in making the model grid search-able with <i>GridSearchCV</i> for automated parameters tuning and behaves well with others when combined in a <i>Pipeline</i>.\n",
    "\n",
    "<strong>TransformerMixin</strong> is a simple class that provides a <i>.fit_transform</i> method that does <i>.fit</i> and <i>.transform</i> and it works well with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MemoryTagger(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Expects a list of words as X and a list of tags as y.\n",
    "        '''\n",
    "        voc = {}\n",
    "        self.tags = []\n",
    "        for x, t in zip(X, y):\n",
    "            if t not in self.tags:\n",
    "                self.tags.append(t)\n",
    "            if x in voc:\n",
    "                if t in voc[x]:\n",
    "                    voc[x][t] += 1\n",
    "                else:\n",
    "                    voc[x][t] = 1\n",
    "            else:\n",
    "                voc[x] = {t: 1}\n",
    "        self.memory = {}\n",
    "        for k, d in voc.items():\n",
    "            self.memory[k] = max(d, key=d.get)\n",
    "        return self.memory\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        '''\n",
    "        Predict the the tag from memory. If word is unknown, predict 'O'.\n",
    "        '''\n",
    "        return [self.memory.get(x, 'O') for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Thousands': 'O', 'of': 'O', 'demonstrators': 'O', 'have': 'O', 'marched': 'O', 'through': 'O', 'London': 'B-geo', 'to': 'O', 'protest': 'O', 'the': 'O', 'war': 'O', 'in': 'O', 'Iraq': 'B-geo', 'and': 'O', 'demand': 'O', 'withdrawal': 'O', 'British': 'B-gpe', 'troops': 'O', 'from': 'O', 'that': 'O', 'country': 'O', '.': 'O'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['O', 'B-geo', 'B-gpe']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize tagger\n",
    "tagger = MemoryTagger()\n",
    "\n",
    "# Fit the tagger\n",
    "print(tagger.fit(sentence, tag))\n",
    "\n",
    "# Getting all unique tags\n",
    "tagger.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_words = pd_dataset['Word'].values.tolist()\n",
    "all_tags = pd_dataset['Tag'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap on classfication report metrics\n",
    "1) Precision (Low Precision = High False Positive)<br> \n",
    "<li>The ability of the classifier not to label as positive a sample that is negative.</li>\n",
    "\n",
    "2) Recall (Low Recall = High False Negative)<br> \n",
    "<li>The ability of the classifier to find all the positive samples.</li>\n",
    "\n",
    "3) f1-score <br>\n",
    "<li>A weighted average of the precision and recall, where an f1 score reaches its best value at 1 and worst score at 0.</li>\n",
    "\n",
    "4) support <br>\n",
    "<li>The number of instances in the test set that have true label.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.20      0.05      0.09       402\n",
      "      B-eve       0.54      0.25      0.34       308\n",
      "      B-geo       0.78      0.85      0.81     37644\n",
      "      B-gpe       0.94      0.93      0.94     15870\n",
      "      B-nat       0.42      0.28      0.33       201\n",
      "      B-org       0.67      0.49      0.56     20143\n",
      "      B-per       0.78      0.65      0.71     16990\n",
      "      B-tim       0.87      0.77      0.82     20333\n",
      "      I-art       0.04      0.01      0.01       297\n",
      "      I-eve       0.39      0.12      0.18       253\n",
      "      I-geo       0.73      0.58      0.65      7414\n",
      "      I-gpe       0.62      0.45      0.52       198\n",
      "      I-nat       0.00      0.00      0.00        51\n",
      "      I-org       0.69      0.53      0.60     16784\n",
      "      I-per       0.73      0.65      0.69     17251\n",
      "      I-tim       0.58      0.13      0.21      6528\n",
      "          O       0.97      0.99      0.98    887908\n",
      "\n",
      "avg / total       0.94      0.95      0.94   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting respective tags\n",
    "pred = cross_val_predict(estimator=MemoryTagger(), X=all_words, y=all_tags, cv=5)\n",
    "\n",
    "report = classification_report(y_pred=pred, y_true=all_tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall value is relatively low and signifies that it is weak. This is mainly because we are unable to predict on words we don't know about. Now for the fun part, let's apply some machine learning models and see which works best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.00      0.00      0.00       402\n",
      "      B-eve       0.00      0.00      0.00       308\n",
      "      B-geo       0.26      0.79      0.40     37644\n",
      "      B-gpe       0.26      0.06      0.09     15870\n",
      "      B-nat       0.00      0.00      0.00       201\n",
      "      B-org       0.65      0.17      0.27     20143\n",
      "      B-per       0.97      0.20      0.33     16990\n",
      "      B-tim       0.29      0.32      0.30     20333\n",
      "      I-art       0.00      0.00      0.00       297\n",
      "      I-eve       0.00      0.00      0.00       253\n",
      "      I-geo       0.00      0.00      0.00      7414\n",
      "      I-gpe       0.00      0.00      0.00       198\n",
      "      I-nat       0.00      0.00      0.00        51\n",
      "      I-org       0.36      0.03      0.06     16784\n",
      "      I-per       0.47      0.02      0.04     17251\n",
      "      I-tim       0.50      0.06      0.11      6528\n",
      "          O       0.97      0.98      0.97    887908\n",
      "\n",
      "avg / total       0.88      0.87      0.86   1048575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# These simple features are created using methods in python library\n",
    "def feature_map(word):\n",
    "    '''Simple feature map.'''\n",
    "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
    "                     word.isdigit(),  word.isalpha()])\n",
    "\n",
    "words = [feature_map(w) for w in pd_dataset[\"Word\"].values.tolist()]\n",
    "\n",
    "pred = cross_val_predict(RandomForestClassifier(n_estimators=20),\n",
    "                         X=words, y=all_tags, cv=5)\n",
    "\n",
    "report = classification_report(y_pred=pred, y_true=all_tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results worsened and this can be attributed to the lack of information necessary for the decision to be made. Next, we shall enhance our simple features by memory and also, context information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "<strong>Label-Encoding</strong><br>\n",
    "In essence, label-encoding is used to transform categorical data into suitable numeric values. It converts each value in a column to a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memory_tagger = MemoryTagger()\n",
    "        self.tag_encoder = LabelEncoder()\n",
    "        self.pos_encoder = LabelEncoder()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        words = X[\"Word\"].values.tolist()\n",
    "        self.pos = X[\"POS\"].values.tolist()\n",
    "        tags = X[\"Tag\"].values.tolist()\n",
    "        self.memory_tagger.fit(all_words, all_tags)\n",
    "        self.tag_encoder.fit(all_tags)\n",
    "        self.pos_encoder.fit(self.pos)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        def pos_default(p):\n",
    "            if p in self.pos:\n",
    "                return self.pos_encoder.transform([p])[0]\n",
    "            else:\n",
    "                return -1\n",
    "        \n",
    "        pos = X[\"POS\"].values.tolist()\n",
    "        words = X[\"Word\"].values.tolist()\n",
    "        out = []\n",
    "        for i in range(len(words)):\n",
    "            w = words[i]\n",
    "            p = pos[i]\n",
    "            if i < len(words) - 1:\n",
    "                wp = self.tag_encoder.transform(self.memory_tagger.predict([words[i+1]]))[0]\n",
    "                posp = pos_default(pos[i+1])\n",
    "            else:\n",
    "                wp = self.tag_encoder.transform(['O'])[0]\n",
    "                posp = pos_default(\".\")\n",
    "            if i > 0:\n",
    "                if words[i-1] != \".\":\n",
    "                    wm = self.tag_encoder.transform(self.memory_tagger.predict([words[i-1]]))[0]\n",
    "                    posm = pos_default(pos[i-1])\n",
    "                else:\n",
    "                    wm = self.tag_encoder.transform(['O'])[0]\n",
    "                    posm = pos_default(\".\")\n",
    "            else:\n",
    "                posm = pos_default(\".\")\n",
    "                wm = self.tag_encoder.transform(['O'])[0]\n",
    "            out.append(np.array([w.istitle(), w.islower(), w.isupper(), len(w), w.isdigit(), w.isalpha(),\n",
    "                                 self.tag_encoder.transform(self.memory_tagger.predict([w]))[0],\n",
    "                                 pos_default(p), wp, wm, posp, posm]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn Pipeline\n",
    "\n",
    "Next, we will use the pipeline from scikit-learn to build our model.<br>\n",
    "Pipeline lists the steps that our model puts the text corpus through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.54      0.36      0.43       402\n",
      "      B-eve       0.47      0.28      0.35       308\n",
      "      B-geo       0.84      0.90      0.87     37644\n",
      "      B-gpe       0.98      0.93      0.96     15870\n",
      "      B-nat       0.46      0.23      0.31       201\n",
      "      B-org       0.78      0.71      0.75     20143\n",
      "      B-per       0.86      0.86      0.86     16990\n",
      "      B-tim       0.90      0.82      0.86     20333\n",
      "      I-art       0.37      0.14      0.20       297\n",
      "      I-eve       0.27      0.13      0.18       253\n",
      "      I-geo       0.79      0.72      0.75      7414\n",
      "      I-gpe       0.72      0.47      0.57       198\n",
      "      I-nat       0.86      0.24      0.37        51\n",
      "      I-org       0.80      0.77      0.78     16784\n",
      "      I-per       0.89      0.89      0.89     17251\n",
      "      I-tim       0.84      0.54      0.66      6528\n",
      "          O       0.99      1.00      0.99    887908\n",
      "\n",
      "avg / total       0.97      0.97      0.97   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pred = cross_val_predict(Pipeline([(\"feature_map\", FeatureTransformer()), \n",
    "                                   (\"clf\", RandomForestClassifier(n_estimators=20, n_jobs=3))]),\n",
    "                         X=pd_dataset, y=all_tags, cv=5)\n",
    "\n",
    "report = classification_report(y_pred=pred, y_true=all_tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results have shown an improvement, showing feature engineering being an integral step in word-processing. Nonetheless, this is just an implementation of simple features and way more can be done to improve the outcome."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import abc\n",
    "from urllib.request import urlopen as url\n",
    "\n",
    "\n",
    "# must be passed raw html\n",
    "class Recipe:\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    title = ''\n",
    "    date = ''\n",
    "    desc = ''\n",
    "    ingredients = []\n",
    "    directions = []\n",
    "    categories = []\n",
    "\n",
    "    @abc.abstractstaticmethod\n",
    "    def get_title(self, page):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractstaticmethod\n",
    "    def get_ingredients(self, page):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractstaticmethod\n",
    "    def get_directions(self, page):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractstaticmethod\n",
    "    def get_categories(self, page):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractstaticmethod\n",
    "    def get_date(self, page):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractstaticmethod\n",
    "    def get_desc(self, page):\n",
    "        pass\n",
    "\n",
    "    def build_recipie(self, page):\n",
    "        self.title = self.get_title(page)\n",
    "        self.ingredients = self.get_ingredients(page)\n",
    "        self.directions = self.get_directions(page)\n",
    "        self.categories = self.get_categories(page)\n",
    "        self.date = self.get_date(page)\n",
    "        self.desc = self.get_desc(page)\n",
    "\n",
    "    def __init__(self, page):\n",
    "        print('attempting to build from: '+page)\n",
    "        try:\n",
    "            self.build_recipie(bs(url(page), 'html.parser'))\n",
    "        except Exception as x:\n",
    "            print('Could not build from %s, %s'%(page,x))\n",
    "\n",
    "class FN_Recipe(Recipe):\n",
    "    def get_title(self, page):\n",
    "        return page.find('div', {'class': 'tier-3 title'}).text.encode('utf-8').strip()\n",
    "\n",
    "    def get_ingredients(self, page):\n",
    "        return [i.text.encode('utf-8').strip() for i in\n",
    "                page.find_all('div', {'class': 'ingredients'})[0].find_all('li')]\n",
    "\n",
    "    def get_directions(self, page):\n",
    "        return [i.text.encode('utf-8').strip() for i in\n",
    "                page.find_all('ul', {'class': 'recipe-directions-list'})[0].find_all('li')]\n",
    "\n",
    "    def get_categories(self, page):\n",
    "        return [i.text.encode('utf-8').strip() for i in page.find_all('ul', {'class': 'categories'})[0].find_all('li')]\n",
    "\n",
    "    def get_date(self, page):\n",
    "        try:\n",
    "            page_s = str(page)\n",
    "            return page_s[page_s.index('OrigPubDate') + 14:page_s.index('OrigPubDate') + 24]\n",
    "        except:\n",
    "            return ''\n",
    "\n",
    "    def get_desc(self, page):\n",
    "        return [dd['content'] for dd in page.find_all('meta', {'itemprop': 'description'})][-1].encode('utf-8').strip()\n",
    "\n",
    "\n",
    "# No scripting shit apparently needed\n",
    "class EP_Recipe(Recipe):\n",
    "    rating = None\n",
    "    calories = None\n",
    "    sodium = None\n",
    "    fat = None\n",
    "    protein = None\n",
    "\n",
    "\n",
    "    def get_date(self, page):\n",
    "        try:\n",
    "            return page.find('meta', {'itemprop': 'datePublished'})['content']\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def get_desc(self, page):\n",
    "        try:\n",
    "            return page.find('div', {'itemprop': 'description'}).find('p').text\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def get_directions(self, page):\n",
    "        return [i.text.strip() for i in page.find_all('li', {'class': \"preparation-step\"})]\n",
    "\n",
    "    def get_ingredients(self, page):\n",
    "        return [i.text.strip() for i in page.find_all('li', {'itemprop': \"ingredients\"})]\n",
    "\n",
    "    def get_categories(self, page):\n",
    "        return [i.text for i in page.find_all('dt', {'itemprop': \"recipeCategory\"})]\n",
    "\n",
    "    def get_title(self, page):\n",
    "        return page.find('h1', {'itemprop': 'name'}).text\n",
    "\n",
    "    def get_rating(self, page):\n",
    "        try:\n",
    "            return float(page.find_all('span', {'class': 'rating'})[-1].text.split('/')[0]) * 5 / 4\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def build_recipie(self, page):\n",
    "        super(EP_Recipe, self).build_recipie(page)\n",
    "        self.rating = self.get_rating(page)\n",
    "        self.calories = self.get_calories(page)\n",
    "        self.sodium = self.get_sodium(page)\n",
    "        self.fat = self.get_fat(page)\n",
    "        self.protein = self.get_protein(page)\n",
    "\n",
    "    def get_calories(self,page):\n",
    "        try:\n",
    "            return float(page.find('span',{'class':'nutri-data','itemprop':'calories'}).text)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def get_sodium(self,page):\n",
    "        try:\n",
    "            return float(page.find('span',{'class':'nutri-data','itemprop':'sodiumContent'}).text.split(' ')[0])\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def get_fat(self, page):\n",
    "        try:\n",
    "            return float(page.find('span', {'class': 'nutri-data', 'itemprop': 'fatContent'}).text.split(' ')[0])\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def get_protein(self, page):\n",
    "        try:\n",
    "            return float(page.find('span', {'class': 'nutri-data', 'itemprop': 'proteinContent'}).text.split(' ')[0])\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import pickle\n",
    "    import json\n",
    "    import multiprocessing\n",
    "    # ep_urls = pickle.load(open('epi_urls.checkpoint','rb'))\n",
    "    # ep_urls = [str(i) for i in ep_urls]\n",
    "    # p = multiprocessing.Pool(4)\n",
    "    # output = p.map(EP_Recipe,ep_urls)\n",
    "    # pickle.dump(output,open('epi_recipes.final','wb'))\n",
    "    data = pickle.load(open('epi_recipes.final','rb'))\n",
    "    ar = []\n",
    "    for i in data:\n",
    "        ar.append(i.__dict__)\n",
    "    pickle.dump(ar,open('epi_recipe_dict_form.dict','wb'))\n",
    "\n",
    "    with open('result.json', 'w') as fp:\n",
    "        json.dump(ar, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
